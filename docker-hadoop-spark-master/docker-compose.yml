version: "3"

services:
  # --- HADOOP CLUSTER ---
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9010:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      CORE_CONF_fs_defaultFS: hdfs://namenode:9000
    ports:
      - "9864:9864"
    env_file:
      - ./hadoop.env

  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864"
    env_file:
      - ./hadoop.env

  nodemanager:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    environment:
      SERVICE_PRECONDITION: "namenode:9870 resourcemanager:8088"
    env_file:
      - ./hadoop.env

  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  # --- SPARK CLUSTER (Unified on Apache Images) ---
  spark-master:
    image: apache/spark-py:latest
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - SPARK_MASTER_HOST=spark-master
      - _JAVA_OPTIONS=--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED
    volumes:
      - C:/Users/Utilisateur/Documents/Cour/Big Data Framework/framework_finaltp/data:/opt/spark/work-dir/data
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    

  spark-worker-1:
    image: apache/spark-py:latest
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_DIR=/tmp/spark-work
      - _JAVA_OPTIONS=--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED
    volumes:
      - C:/Users/Utilisateur/Documents/Cour/Big Data Framework/framework_finaltp/data:/opt/spark/work-dir/data
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  spark-submit:
    image: apache/spark-py:latest
    container_name: spark-submit
    user: root
    depends_on:
      - spark-master
    environment:
      - _JAVA_OPTIONS=--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED
    volumes:
      - C:/Users/Utilisateur/Documents/Cour/Big Data Framework/framework_finaltp/src:/opt/spark/work-dir/src
      - C:/Users/Utilisateur/Documents/Cour/Big Data Framework/framework_finaltp/data:/opt/spark/work-dir/data
    working_dir: /opt/spark/work-dir
    command: >
      /bin/sh -c "sleep 5 && 
      /opt/spark/bin/spark-submit 
      --master spark://spark-master:7077 
      /opt/spark/work-dir/src/bronze/feeder.py"

  # --- HIVE & PRESTO ---
  hive-metastore-postgresql:
    image: bde2020/hive-metastore-postgresql:2.3.0
    container_name: hive-metastore-postgresql

  hive-metastore:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-metastore
    depends_on:
      - hive-metastore-postgresql
    env_file:
      - ./hadoop-hive.env
    command: /opt/hive/bin/hive --service metastore

  hive-server:
    image: bde2020/hive:2.3.2-postgresql-metastore
    container_name: hive-server
    depends_on:
      - hive-metastore
    ports:
      - "10000:10000"
    env_file:
      - ./hadoop-hive.env

  presto-coordinator:
    image: shawnzhu/prestodb:0.181
    container_name: presto-coordinator
    ports:
      - "8089:8089"

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver: